{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c6e0f8f-243b-4884-abef-3a54b029e2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -c \"import monai\" || pip install -q \"monai-weekly[nibabel]\"\n",
    "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a462a7a-18c2-4c37-9ff3-9a706b7f5312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MONAI version: 1.2.0\n",
      "Numpy version: 1.23.5\n",
      "Pytorch version: 2.0.1+cu117\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: c33f1ba588ee00229a309000e888f9817b4f1934\n",
      "MONAI __file__: /home/sjavaji_umass_edu/.local/lib/python3.9/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "ITK version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "Nibabel version: 5.1.0\n",
      "scikit-image version: 0.19.2\n",
      "Pillow version: 9.2.0\n",
      "Tensorboard version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "gdown version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "TorchVision version: 0.15.2+cu117\n",
      "tqdm version: 4.64.1\n",
      "lmdb version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "psutil version: 5.9.0\n",
      "pandas version: 1.4.4\n",
      "einops version: 0.6.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai import data\n",
    "from monai.data import decollate_batch\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "print_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a404104a-091f-4cf5-82a9-26d4472dfb1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/tmprk1qts9y\n"
     ]
    }
   ],
   "source": [
    "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
    "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
    "print(root_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "02bdbb4a-ebea-4470-a6a4-73c8f20ee1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "import monai.transforms as transforms\n",
    "import monai.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d3bce40-8bfa-4462-9d79-c93c68f8fd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = np.where(self.count > 0, self.sum / self.count, self.sum)\n",
    "\n",
    "\n",
    "def datafold_read(datalist, basedir, fold=0, key=\"training\"):\n",
    "    with open(datalist) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    json_data = json_data[key]\n",
    "\n",
    "    for d in json_data:\n",
    "        for k in d:\n",
    "            if isinstance(d[k], list):\n",
    "                d[k] = [os.path.join(basedir, iv) for iv in d[k]]\n",
    "            elif isinstance(d[k], str):\n",
    "                d[k] = os.path.join(basedir, d[k]) if len(d[k]) > 0 else d[k]\n",
    "\n",
    "    tr = []\n",
    "    val = []\n",
    "    for d in json_data:\n",
    "        if \"fold\" in d and d[\"fold\"] == fold:\n",
    "            val.append(d)\n",
    "        else:\n",
    "            tr.append(d)\n",
    "\n",
    "    return tr, val\n",
    "\n",
    "\n",
    "def save_checkpoint(model, epoch, filename=\"model.pt\", best_acc=0, dir_add=root_dir):\n",
    "    state_dict = model.state_dict()\n",
    "    save_dict = {\"epoch\": epoch, \"best_acc\": best_acc, \"state_dict\": state_dict}\n",
    "    filename = os.path.join(dir_add, filename)\n",
    "    torch.save(save_dict, filename)\n",
    "    print(\"Saving checkpoint\", filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "715dccb6-3b86-48ed-8ae4-e07228eddf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    EnsureChannelFirstd,\n",
    "    LoadImaged,\n",
    "    MapTransform,\n",
    "    NormalizeIntensityd,\n",
    "    Orientationd,\n",
    "    RandFlipd,\n",
    "    RandScaleIntensityd,\n",
    "    RandShiftIntensityd,\n",
    "    RandSpatialCropd,\n",
    "    Spacingd,\n",
    "    ToDeviced,\n",
    ")\n",
    "class ConvertToMultiChannelBasedOnBratsClassesd(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels to multi channels based on brats classes:\n",
    "    label 1 is the peritumoral edema\n",
    "    label 2 is the GD-enhancing tumor\n",
    "    label 3 is the necrotic and non-enhancing tumor core\n",
    "    The possible classes are TC (Tumor core), WT (Whole tumor)\n",
    "    and ET (Enhancing tumor).\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "            result = []\n",
    "            #NCR\n",
    "            result.append(d[key] == 1)\n",
    "            # ED\n",
    "            result.append(d[key] == 2)\n",
    "            # label 2 is ET\n",
    "            result.append(d[key] == 3)\n",
    "            d[key] = torch.stack(result, dim=0)\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d3926665-e669-485c-a7f2-872b1a8c4d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(batch_size, data_dir, json_list, fold, roi):\n",
    "    data_dir = data_dir\n",
    "    datalist_json = json_list\n",
    "    train_files, validation_files = datafold_read(datalist=datalist_json, basedir=data_dir, fold=fold)\n",
    "    train_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "            transforms.CropForegroundd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                source_key=\"image\",\n",
    "                k_divisible=[roi[0], roi[1], roi[2]],\n",
    "            ),\n",
    "            transforms.RandSpatialCropd(\n",
    "                keys=[\"image\", \"label\"],\n",
    "                roi_size=[roi[0], roi[1], roi[2]],\n",
    "                random_size=False,\n",
    "            ),\n",
    "            transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=0),\n",
    "            transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=1),\n",
    "            transforms.RandFlipd(keys=[\"image\", \"label\"], prob=0.5, spatial_axis=2),\n",
    "            transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "            transforms.RandScaleIntensityd(keys=\"image\", factors=0.1, prob=1.0),\n",
    "            transforms.RandShiftIntensityd(keys=\"image\", offsets=0.1, prob=1.0),\n",
    "        ]\n",
    "    )\n",
    "    val_transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "            ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "            transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    train_ds = monai.data.Dataset(data=train_files, transform=train_transform)\n",
    "\n",
    "    train_loader = monai.data.DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    val_ds = monai.data.Dataset(data=validation_files, transform=val_transform)\n",
    "    val_loader = monai.data.DataLoader(\n",
    "        val_ds,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=8,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a79d7eba-0290-4850-bb40-025916d5da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import random\n",
    "\n",
    "# Specify the directory paths for your images and labels\n",
    "t1c_dir = 'pediatric_modalities/t1c'\n",
    "t2f_dir = 'pediatric_modalities/t2f'\n",
    "seg_dir = 'pediatric_modalities/seg'\n",
    "\n",
    "# Create an empty list to hold the data\n",
    "data = {'training': []}\n",
    "\n",
    "# Get all file names in the t1c_dir\n",
    "t1c_files = os.listdir(t1c_dir)\n",
    "\n",
    "# Sort the files to ensure matching order across different directories\n",
    "t1c_files.sort()\n",
    "\n",
    "# Set the fold size for 80% training data\n",
    "fold_size = int(0.8 * len(t1c_files))\n",
    "\n",
    "# Loop through each t1c file\n",
    "for i, t1c_file in enumerate(t1c_files):\n",
    "    # Extract the base file name without the extension\n",
    "    base_file_name = t1c_file.replace('.nii.gz', '')\n",
    "    \n",
    "    # Construct the corresponding t2f and seg file names\n",
    "    t2f_file = base_file_name.replace('t1c', 't2f') + '.nii.gz'\n",
    "    seg_file = base_file_name.replace('t1c', 'seg') + '.nii.gz'\n",
    "\n",
    "    # Set the fold as 0 for the first 80% of data, and 1 for the remaining 20%\n",
    "    fold = 0 if i < fold_size else 1\n",
    "    \n",
    "    # Add the data to the list\n",
    "    data['training'].append({\n",
    "        'fold': fold,\n",
    "        'image': [\n",
    "            os.path.join(t1c_dir, t1c_file),\n",
    "            os.path.join(t2f_dir, t2f_file)\n",
    "        ],\n",
    "        'label': os.path.join(seg_dir, seg_file)\n",
    "    })\n",
    "\n",
    "# Now we have a list with all the data, we can write it to a JSON file\n",
    "with open('training_data.json', 'w') as outfile:\n",
    "    json.dump(data, outfile, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a4aadd3c-aebd-46e6-8509-024c8a331e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"\"\n",
    "json_list = \"training_data.json\"\n",
    "roi = (128, 128, 128)\n",
    "batch_size = 2\n",
    "sw_batch_size = 2\n",
    "fold = 1\n",
    "infer_overlap = 0.5\n",
    "max_epochs = 100\n",
    "val_every = 1\n",
    "train_loader, val_loader = get_loader(batch_size, data_dir, json_list, fold, roi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8706038-028c-4e7a-8ba4-f35436872e9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98b6ce28-b6d1-4fc5-bb11-1153e2c77fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=roi,\n",
    "    in_channels=2,\n",
    "    out_channels=3,\n",
    "    feature_size=48,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    use_checkpoint=True,\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "80ca40eb-efc2-4938-9e4a-fcaaae480799",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True\n",
    "dice_loss = DiceLoss(to_onehot_y=False, sigmoid=True)\n",
    "post_sigmoid = Activations(sigmoid=True)\n",
    "post_pred = AsDiscrete(argmax=False, threshold=0.5)\n",
    "dice_acc = DiceMetric(include_background=True, reduction=MetricReduction.MEAN_BATCH, get_not_nans=True)\n",
    "model_inferer = partial(\n",
    "    sliding_window_inference,\n",
    "    roi_size=[roi[0], roi[1], roi[2]],\n",
    "    sw_batch_size=sw_batch_size,\n",
    "    predictor=model,\n",
    "    overlap=infer_overlap,\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f4457039-5e6d-461a-bcfa-efafe8a137a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, epoch, loss_func):\n",
    "    model.train()\n",
    "    start_time = time.time()\n",
    "    run_loss = AverageMeter()\n",
    "    for idx, batch_data in enumerate(loader):\n",
    "        data, target = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "        logits = model(data)\n",
    "        loss = loss_func(logits, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        run_loss.update(loss.item(), n=batch_size)\n",
    "        print(\n",
    "            \"Epoch {}/{} {}/{}\".format(epoch, max_epochs, idx, len(loader)),\n",
    "            \"loss: {:.4f}\".format(run_loss.avg),\n",
    "            \"time {:.2f}s\".format(time.time() - start_time),\n",
    "        )\n",
    "        start_time = time.time()\n",
    "    return run_loss.avg\n",
    "\n",
    "\n",
    "def val_epoch(\n",
    "    model,\n",
    "    loader,\n",
    "    epoch,\n",
    "    acc_func,\n",
    "    model_inferer=None,\n",
    "    post_sigmoid=None,\n",
    "    post_pred=None,\n",
    "):\n",
    "    model.eval()\n",
    "    start_time = time.time()\n",
    "    run_acc = AverageMeter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, batch_data in enumerate(loader):\n",
    "            data, target = batch_data[\"image\"].to(device), batch_data[\"label\"].to(device)\n",
    "            logits = model_inferer(data)\n",
    "            val_labels_list = decollate_batch(target)\n",
    "            val_outputs_list = decollate_batch(logits)\n",
    "            val_output_convert = [post_pred(post_sigmoid(val_pred_tensor)) for val_pred_tensor in val_outputs_list]\n",
    "            acc_func.reset()\n",
    "            acc_func(y_pred=val_output_convert, y=val_labels_list)\n",
    "            acc, not_nans = acc_func.aggregate()\n",
    "            run_acc.update(acc.cpu().numpy(), n=not_nans.cpu().numpy())\n",
    "            dice_tc = run_acc.avg[0]\n",
    "            dice_wt = run_acc.avg[1]\n",
    "            dice_et = run_acc.avg[2]\n",
    "            print(\n",
    "                \"Val {}/{} {}/{}\".format(epoch, max_epochs, idx, len(loader)),\n",
    "                \", dice_tc:\",\n",
    "                dice_tc,\n",
    "                \", dice_wt:\",\n",
    "                dice_wt,\n",
    "                \", dice_et:\",\n",
    "                dice_et,\n",
    "                \", time {:.2f}s\".format(time.time() - start_time),\n",
    "            )\n",
    "            start_time = time.time()\n",
    "\n",
    "    return run_acc.avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eef0951d-8d33-465d-98dc-8653cfd54030",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    optimizer,\n",
    "    loss_func,\n",
    "    acc_func,\n",
    "    scheduler,\n",
    "    model_inferer=None,\n",
    "    start_epoch=0,\n",
    "    post_sigmoid=None,\n",
    "    post_pred=None,\n",
    "):\n",
    "    val_acc_max = 0.0\n",
    "    dices_tc = []\n",
    "    dices_wt = []\n",
    "    dices_et = []\n",
    "    dices_avg = []\n",
    "    loss_epochs = []\n",
    "    trains_epoch = []\n",
    "    for epoch in range(start_epoch, max_epochs):\n",
    "        print(time.ctime(), \"Epoch:\", epoch)\n",
    "        epoch_time = time.time()\n",
    "        train_loss = train_epoch(\n",
    "            model,\n",
    "            train_loader,\n",
    "            optimizer,\n",
    "            epoch=epoch,\n",
    "            loss_func=loss_func,\n",
    "        )\n",
    "        print(\n",
    "            \"Final training  {}/{}\".format(epoch, max_epochs - 1),\n",
    "            \"loss: {:.4f}\".format(train_loss),\n",
    "            \"time {:.2f}s\".format(time.time() - epoch_time),\n",
    "        )\n",
    "\n",
    "        if (epoch + 1) % val_every == 0 or epoch == 0:\n",
    "            loss_epochs.append(train_loss)\n",
    "            trains_epoch.append(int(epoch))\n",
    "            epoch_time = time.time()\n",
    "            val_acc = val_epoch(\n",
    "                model,\n",
    "                val_loader,\n",
    "                epoch=epoch,\n",
    "                acc_func=acc_func,\n",
    "                model_inferer=model_inferer,\n",
    "                post_sigmoid=post_sigmoid,\n",
    "                post_pred=post_pred,\n",
    "            )\n",
    "            print(val_acc)\n",
    "            dice_tc = val_acc[0]\n",
    "            dice_wt = val_acc[1]\n",
    "            dice_et = val_acc[2]\n",
    "            val_avg_acc = np.mean(val_acc)\n",
    "            print(\n",
    "                \"Final validation stats {}/{}\".format(epoch, max_epochs - 1),\n",
    "                \", dice_tc:\",\n",
    "                dice_tc,\n",
    "                \", dice_wt:\",\n",
    "                dice_wt,\n",
    "                \", dice_et:\",\n",
    "                dice_et,\n",
    "                \", Dice_Avg:\",\n",
    "                val_avg_acc,\n",
    "                \", time {:.2f}s\".format(time.time() - epoch_time),\n",
    "            )\n",
    "            dices_tc.append(dice_tc)\n",
    "            dices_wt.append(dice_wt)\n",
    "            dices_et.append(dice_et)\n",
    "            dices_avg.append(val_avg_acc)\n",
    "            if val_avg_acc > val_acc_max:\n",
    "                print(\"new best ({:.6f} --> {:.6f}). \".format(val_acc_max, val_avg_acc))\n",
    "                val_acc_max = val_avg_acc\n",
    "                save_checkpoint(\n",
    "                    model,\n",
    "                    epoch,\n",
    "                    best_acc=val_acc_max,\n",
    "                )\n",
    "            scheduler.step()\n",
    "    print(\"Training Finished !, Best Accuracy: \", val_acc_max)\n",
    "    return (\n",
    "        val_acc_max,\n",
    "        dices_tc,\n",
    "        dices_wt,\n",
    "        dices_et,\n",
    "        dices_avg,\n",
    "        loss_epochs,\n",
    "        trains_epoch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031fc804-a009-4be2-9712-1441a8dcd01a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jul  5 20:44:38 2023 Epoch: 0\n",
      "Epoch 0/100 0/40 loss: 0.9925 time 6.21s\n",
      "Epoch 0/100 1/40 loss: 0.9834 time 2.34s\n",
      "Epoch 0/100 2/40 loss: 0.9884 time 2.36s\n",
      "Epoch 0/100 3/40 loss: 0.9888 time 2.37s\n",
      "Epoch 0/100 4/40 loss: 0.9902 time 2.38s\n",
      "Epoch 0/100 5/40 loss: 0.9804 time 2.40s\n",
      "Epoch 0/100 6/40 loss: 0.9793 time 2.40s\n",
      "Epoch 0/100 7/40 loss: 0.9806 time 2.42s\n",
      "Epoch 0/100 8/40 loss: 0.9814 time 2.44s\n",
      "Epoch 0/100 9/40 loss: 0.9809 time 2.45s\n",
      "Epoch 0/100 10/40 loss: 0.9815 time 2.47s\n",
      "Epoch 0/100 11/40 loss: 0.9825 time 2.47s\n",
      "Epoch 0/100 12/40 loss: 0.9771 time 2.47s\n",
      "Epoch 0/100 13/40 loss: 0.9784 time 2.48s\n",
      "Epoch 0/100 14/40 loss: 0.9791 time 2.49s\n",
      "Epoch 0/100 15/40 loss: 0.9796 time 2.48s\n",
      "Epoch 0/100 16/40 loss: 0.9805 time 2.50s\n",
      "Epoch 0/100 17/40 loss: 0.9800 time 2.50s\n",
      "Epoch 0/100 18/40 loss: 0.9802 time 2.51s\n",
      "Epoch 0/100 19/40 loss: 0.9805 time 2.50s\n",
      "Epoch 0/100 20/40 loss: 0.9807 time 2.49s\n",
      "Epoch 0/100 21/40 loss: 0.9793 time 2.52s\n",
      "Epoch 0/100 22/40 loss: 0.9776 time 2.48s\n",
      "Epoch 0/100 23/40 loss: 0.9776 time 2.54s\n",
      "Epoch 0/100 24/40 loss: 0.9776 time 2.51s\n",
      "Epoch 0/100 25/40 loss: 0.9781 time 2.54s\n",
      "Epoch 0/100 26/40 loss: 0.9777 time 2.53s\n",
      "Epoch 0/100 27/40 loss: 0.9779 time 2.49s\n",
      "Epoch 0/100 28/40 loss: 0.9779 time 2.53s\n",
      "Epoch 0/100 29/40 loss: 0.9775 time 2.50s\n",
      "Epoch 0/100 30/40 loss: 0.9774 time 2.54s\n",
      "Epoch 0/100 31/40 loss: 0.9774 time 2.51s\n",
      "Epoch 0/100 32/40 loss: 0.9765 time 2.51s\n",
      "Epoch 0/100 33/40 loss: 0.9769 time 2.52s\n",
      "Epoch 0/100 34/40 loss: 0.9760 time 2.51s\n",
      "Epoch 0/100 35/40 loss: 0.9757 time 2.52s\n",
      "Epoch 0/100 36/40 loss: 0.9755 time 2.50s\n",
      "Epoch 0/100 37/40 loss: 0.9759 time 2.53s\n",
      "Epoch 0/100 38/40 loss: 0.9762 time 2.49s\n",
      "Epoch 0/100 39/40 loss: 0.9763 time 1.32s\n",
      "Final training  0/99 loss: 0.9763 time 101.83s\n",
      "Val 0/100 0/20 , dice_tc: 0.03554146 , dice_wt: 5.1706174e-06 , dice_et: 0.016173711 , time 8.08s\n",
      "Val 0/100 1/20 , dice_tc: 0.0893207 , dice_wt: 3.7876812e-06 , dice_et: 0.0113991825 , time 5.90s\n",
      "Val 0/100 2/20 , dice_tc: 0.07563288 , dice_wt: 3.7876812e-06 , dice_et: 0.009795235 , time 5.95s\n",
      "Val 0/100 3/20 , dice_tc: 0.08867094 , dice_wt: 3.7876812e-06 , dice_et: 0.02064079 , time 5.97s\n",
      "Val 0/100 4/20 , dice_tc: 0.08539136 , dice_wt: 3.7876812e-06 , dice_et: 0.016879354 , time 5.97s\n",
      "Val 0/100 5/20 , dice_tc: 0.08217668 , dice_wt: 3.7876812e-06 , dice_et: 0.016879354 , time 6.00s\n",
      "Val 0/100 6/20 , dice_tc: 0.07551324 , dice_wt: 3.7876812e-06 , dice_et: 0.015622263 , time 5.95s\n",
      "Val 0/100 7/20 , dice_tc: 0.06809589 , dice_wt: 1.6341202e-05 , dice_et: 0.014179388 , time 6.06s\n",
      "Val 0/100 8/20 , dice_tc: 0.06565813 , dice_wt: 1.6341202e-05 , dice_et: 0.014190264 , time 5.97s\n",
      "Val 0/100 9/20 , dice_tc: 0.067906536 , dice_wt: 1.6341202e-05 , dice_et: 0.012622833 , time 5.98s\n",
      "Val 0/100 10/20 , dice_tc: 0.068756334 , dice_wt: 0.0023536177 , dice_et: 0.011365769 , time 5.99s\n",
      "Val 0/100 11/20 , dice_tc: 0.07339939 , dice_wt: 0.0019023328 , dice_et: 0.019788213 , time 5.98s\n",
      "Val 0/100 12/20 , dice_tc: 0.07180616 , dice_wt: 0.0019023328 , dice_et: 0.018195638 , time 5.98s\n",
      "Val 0/100 13/20 , dice_tc: 0.07092261 , dice_wt: 0.0019284356 , dice_et: 0.018549653 , time 5.96s\n",
      "Val 0/100 14/20 , dice_tc: 0.07328843 , dice_wt: 0.0019284356 , dice_et: 0.019501684 , time 5.99s\n",
      "Val 0/100 15/20 , dice_tc: 0.07913673 , dice_wt: 0.0016542574 , dice_et: 0.01820187 , time 5.99s\n",
      "Val 0/100 16/20 , dice_tc: 0.08438161 , dice_wt: 0.0042740805 , dice_et: 0.021684892 , time 5.97s\n",
      "Val 0/100 17/20 , dice_tc: 0.081602566 , dice_wt: 0.008994435 , dice_et: 0.020651067 , time 5.97s\n",
      "Val 0/100 18/20 , dice_tc: 0.09107875 , dice_wt: 0.0110366475 , dice_et: 0.021026319 , time 5.99s\n",
      "Val 0/100 19/20 , dice_tc: 0.08740264 , dice_wt: 0.0110366475 , dice_et: 0.021026319 , time 5.98s\n",
      "[0.08740264 0.01103665 0.02102632]\n",
      "Final validation stats 0/99 , dice_tc: 0.08740264 , dice_wt: 0.0110366475 , dice_et: 0.021026319 , Dice_Avg: 0.03982187 , time 121.75s\n",
      "new best (0.000000 --> 0.039822). \n",
      "Saving checkpoint /tmp/tmprk1qts9y/model.pt\n",
      "Wed Jul  5 20:48:23 2023 Epoch: 1\n",
      "Epoch 1/100 0/40 loss: 0.9389 time 6.60s\n",
      "Epoch 1/100 1/40 loss: 0.9651 time 2.42s\n",
      "Epoch 1/100 2/40 loss: 0.9748 time 2.47s\n",
      "Epoch 1/100 3/40 loss: 0.9755 time 2.48s\n",
      "Epoch 1/100 4/40 loss: 0.9679 time 2.50s\n",
      "Epoch 1/100 5/40 loss: 0.9706 time 2.51s\n",
      "Epoch 1/100 6/40 loss: 0.9739 time 2.50s\n",
      "Epoch 1/100 7/40 loss: 0.9755 time 2.52s\n",
      "Epoch 1/100 8/40 loss: 0.9777 time 2.53s\n",
      "Epoch 1/100 9/40 loss: 0.9795 time 2.50s\n",
      "Epoch 1/100 10/40 loss: 0.9809 time 2.60s\n",
      "Epoch 1/100 11/40 loss: 0.9803 time 2.69s\n",
      "Epoch 1/100 12/40 loss: 0.9799 time 2.50s\n",
      "Epoch 1/100 13/40 loss: 0.9796 time 2.58s\n",
      "Epoch 1/100 14/40 loss: 0.9792 time 2.51s\n",
      "Epoch 1/100 15/40 loss: 0.9784 time 2.58s\n",
      "Epoch 1/100 16/40 loss: 0.9770 time 2.54s\n",
      "Epoch 1/100 17/40 loss: 0.9776 time 2.53s\n",
      "Epoch 1/100 18/40 loss: 0.9786 time 2.56s\n",
      "Epoch 1/100 19/40 loss: 0.9788 time 2.53s\n",
      "Epoch 1/100 20/40 loss: 0.9783 time 2.53s\n",
      "Epoch 1/100 21/40 loss: 0.9784 time 2.55s\n",
      "Epoch 1/100 22/40 loss: 0.9782 time 2.53s\n",
      "Epoch 1/100 23/40 loss: 0.9786 time 2.54s\n",
      "Epoch 1/100 24/40 loss: 0.9779 time 2.53s\n",
      "Epoch 1/100 25/40 loss: 0.9780 time 2.55s\n",
      "Epoch 1/100 26/40 loss: 0.9782 time 2.54s\n",
      "Epoch 1/100 27/40 loss: 0.9776 time 2.52s\n",
      "Epoch 1/100 28/40 loss: 0.9770 time 2.53s\n",
      "Epoch 1/100 29/40 loss: 0.9774 time 2.53s\n",
      "Epoch 1/100 30/40 loss: 0.9766 time 2.52s\n",
      "Epoch 1/100 31/40 loss: 0.9768 time 2.52s\n",
      "Epoch 1/100 32/40 loss: 0.9768 time 2.53s\n",
      "Epoch 1/100 33/40 loss: 0.9765 time 2.53s\n",
      "Epoch 1/100 34/40 loss: 0.9763 time 2.53s\n",
      "Epoch 1/100 35/40 loss: 0.9751 time 2.52s\n",
      "Epoch 1/100 36/40 loss: 0.9753 time 2.52s\n",
      "Epoch 1/100 37/40 loss: 0.9753 time 2.53s\n",
      "Epoch 1/100 38/40 loss: 0.9758 time 2.55s\n",
      "Epoch 1/100 39/40 loss: 0.9764 time 1.34s\n",
      "Final training  1/99 loss: 0.9764 time 104.23s\n",
      "Val 1/100 0/20 , dice_tc: 0.044188045 , dice_wt: 3.291428e-06 , dice_et: 0.02148086 , time 8.65s\n",
      "Val 1/100 1/20 , dice_tc: 0.11739352 , dice_wt: 3.332854e-06 , dice_et: 0.01626595 , time 5.95s\n",
      "Val 1/100 2/20 , dice_tc: 0.096870065 , dice_wt: 3.332854e-06 , dice_et: 0.013207272 , time 5.98s\n",
      "Val 1/100 3/20 , dice_tc: 0.11262864 , dice_wt: 3.332854e-06 , dice_et: 0.028875133 , time 6.00s\n",
      "Val 1/100 4/20 , dice_tc: 0.10747291 , dice_wt: 3.332854e-06 , dice_et: 0.023514774 , time 6.00s\n",
      "Val 1/100 5/20 , dice_tc: 0.10655578 , dice_wt: 3.332854e-06 , dice_et: 0.023514774 , time 5.99s\n",
      "Val 1/100 6/20 , dice_tc: 0.09805168 , dice_wt: 3.332854e-06 , dice_et: 0.021587163 , time 6.03s\n",
      "Val 1/100 7/20 , dice_tc: 0.0881763 , dice_wt: 1.8959794e-05 , dice_et: 0.019609941 , time 6.01s\n",
      "Val 1/100 8/20 , dice_tc: 0.088005394 , dice_wt: 1.8959794e-05 , dice_et: 0.019684605 , time 5.98s\n",
      "Val 1/100 9/20 , dice_tc: 0.08889449 , dice_wt: 1.8959794e-05 , dice_et: 0.017508652 , time 5.98s\n",
      "Val 1/100 10/20 , dice_tc: 0.08963668 , dice_wt: 0.0030575113 , dice_et: 0.015766114 , time 5.98s\n",
      "Val 1/100 11/20 , dice_tc: 0.094389044 , dice_wt: 0.0024694041 , dice_et: 0.028314233 , time 6.00s\n",
      "Val 1/100 12/20 , dice_tc: 0.09182762 , dice_wt: 0.0024694041 , dice_et: 0.026030473 , time 5.98s\n",
      "Val 1/100 13/20 , dice_tc: 0.0909934 , dice_wt: 0.0025191323 , dice_et: 0.026303874 , time 5.96s\n",
      "Val 1/100 14/20 , dice_tc: 0.093312174 , dice_wt: 0.0025191323 , dice_et: 0.0273094 , time 5.99s\n",
      "Val 1/100 15/20 , dice_tc: 0.10573797 , dice_wt: 0.0021616896 , dice_et: 0.025488771 , time 5.96s\n",
      "Val 1/100 16/20 , dice_tc: 0.11135451 , dice_wt: 0.005447969 , dice_et: 0.03061616 , time 5.99s\n",
      "Val 1/100 17/20 , dice_tc: 0.1076044 , dice_wt: 0.011347594 , dice_et: 0.029173506 , time 5.97s\n",
      "Val 1/100 18/20 , dice_tc: 0.118407466 , dice_wt: 0.013579254 , dice_et: 0.029459914 , time 5.98s\n",
      "Val 1/100 19/20 , dice_tc: 0.11347471 , dice_wt: 0.013579254 , dice_et: 0.029459914 , time 5.96s\n",
      "[0.11347471 0.01357925 0.02945991]\n",
      "Final validation stats 1/99 , dice_tc: 0.11347471 , dice_wt: 0.013579254 , dice_et: 0.029459914 , Dice_Avg: 0.05217129 , time 122.44s\n",
      "new best (0.039822 --> 0.052171). \n",
      "Saving checkpoint /tmp/tmprk1qts9y/model.pt\n",
      "Wed Jul  5 20:52:10 2023 Epoch: 2\n",
      "Epoch 2/100 0/40 loss: 0.9909 time 5.68s\n",
      "Epoch 2/100 1/40 loss: 0.9874 time 2.42s\n",
      "Epoch 2/100 2/40 loss: 0.9808 time 2.47s\n",
      "Epoch 2/100 3/40 loss: 0.9716 time 2.47s\n",
      "Epoch 2/100 4/40 loss: 0.9749 time 2.51s\n",
      "Epoch 2/100 5/40 loss: 0.9739 time 2.52s\n",
      "Epoch 2/100 6/40 loss: 0.9739 time 2.52s\n",
      "Epoch 2/100 7/40 loss: 0.9753 time 2.49s\n",
      "Epoch 2/100 8/40 loss: 0.9760 time 2.54s\n",
      "Epoch 2/100 9/40 loss: 0.9759 time 2.53s\n",
      "Epoch 2/100 10/40 loss: 0.9777 time 2.51s\n",
      "Epoch 2/100 11/40 loss: 0.9786 time 2.55s\n",
      "Epoch 2/100 12/40 loss: 0.9779 time 2.54s\n",
      "Epoch 2/100 13/40 loss: 0.9735 time 2.53s\n",
      "Epoch 2/100 14/40 loss: 0.9738 time 2.52s\n",
      "Epoch 2/100 15/40 loss: 0.9747 time 2.54s\n",
      "Epoch 2/100 16/40 loss: 0.9758 time 2.53s\n",
      "Epoch 2/100 17/40 loss: 0.9766 time 2.52s\n",
      "Epoch 2/100 18/40 loss: 0.9764 time 2.52s\n",
      "Epoch 2/100 19/40 loss: 0.9771 time 2.58s\n",
      "Epoch 2/100 20/40 loss: 0.9778 time 2.55s\n",
      "Epoch 2/100 21/40 loss: 0.9760 time 2.53s\n",
      "Epoch 2/100 22/40 loss: 0.9761 time 2.54s\n",
      "Epoch 2/100 23/40 loss: 0.9758 time 2.57s\n",
      "Epoch 2/100 24/40 loss: 0.9757 time 2.53s\n",
      "Epoch 2/100 25/40 loss: 0.9749 time 2.53s\n",
      "Epoch 2/100 26/40 loss: 0.9741 time 2.52s\n",
      "Epoch 2/100 27/40 loss: 0.9724 time 2.53s\n",
      "Epoch 2/100 28/40 loss: 0.9722 time 2.55s\n",
      "Epoch 2/100 29/40 loss: 0.9711 time 2.52s\n",
      "Epoch 2/100 30/40 loss: 0.9701 time 2.53s\n",
      "Epoch 2/100 31/40 loss: 0.9705 time 2.52s\n",
      "Epoch 2/100 32/40 loss: 0.9707 time 2.58s\n",
      "Epoch 2/100 33/40 loss: 0.9698 time 2.52s\n",
      "Epoch 2/100 34/40 loss: 0.9691 time 2.50s\n",
      "Epoch 2/100 35/40 loss: 0.9694 time 2.53s\n",
      "Epoch 2/100 36/40 loss: 0.9690 time 2.53s\n",
      "Epoch 2/100 37/40 loss: 0.9694 time 2.51s\n",
      "Epoch 2/100 38/40 loss: 0.9691 time 2.53s\n",
      "Epoch 2/100 39/40 loss: 0.9690 time 1.34s\n",
      "Final training  2/99 loss: 0.9690 time 103.07s\n",
      "Val 2/100 0/20 , dice_tc: 0.08317563 , dice_wt: 0.0 , dice_et: 0.03961447 , time 8.53s\n",
      "Val 2/100 1/20 , dice_tc: 0.21877773 , dice_wt: 1.9156355e-06 , dice_et: 0.028969068 , time 5.96s\n",
      "Val 2/100 2/20 , dice_tc: 0.17849898 , dice_wt: 1.9156355e-06 , dice_et: 0.023039892 , time 5.98s\n",
      "Val 2/100 3/20 , dice_tc: 0.19809075 , dice_wt: 1.9156355e-06 , dice_et: 0.04836665 , time 5.99s\n",
      "Val 2/100 4/20 , dice_tc: 0.1821845 , dice_wt: 1.9156355e-06 , dice_et: 0.03924557 , time 6.00s\n"
     ]
    }
   ],
   "source": [
    "start_epoch = 0\n",
    "\n",
    "(\n",
    "    val_acc_max,\n",
    "    dices_tc,\n",
    "    dices_wt,\n",
    "    dices_et,\n",
    "    dices_avg,\n",
    "    loss_epochs,\n",
    "    trains_epoch,\n",
    ") = trainer(\n",
    "    model=model,\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    optimizer=optimizer,\n",
    "    loss_func=dice_loss,\n",
    "    acc_func=dice_acc,\n",
    "    scheduler=scheduler,\n",
    "    model_inferer=model_inferer,\n",
    "    start_epoch=start_epoch,\n",
    "    post_sigmoid=post_sigmoid,\n",
    "    post_pred=post_pred,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55988100-a6bb-46d7-a597-fe6c94e0f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6e4733-90d7-4e98-b669-d46afe03bce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-2022.10]",
   "language": "python",
   "name": "conda-env-anaconda-2022.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
