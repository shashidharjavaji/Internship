{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "271eb9c3-e21d-45c4-91dd-78bf254d509d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision.transforms import ToTensor\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from medpy.metric import dc, assd\n",
    "import torch.nn.functional as F\n",
    "import torchio as tio\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94776590-bdff-4d9d-a458-3084e00ecc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(UNet, self).__init__()\n",
    "\n",
    "        # Downsample path\n",
    "        self.conv1 = self.double_conv(in_channels, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2 = self.double_conv(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3 = self.double_conv(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4 = self.double_conv(256, 512)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        # Bottom\n",
    "        self.conv5 = self.double_conv(512, 1024)\n",
    "\n",
    "        # Upsample path\n",
    "        self.up6 = nn.ConvTranspose2d(1024, 512, kernel_size = 2, stride = 2)\n",
    "        self.conv6 = self.double_conv(1024, 512)\n",
    "        self.up7 = nn.ConvTranspose2d(512, 256, kernel_size = 2, stride = 2)\n",
    "        self.conv7 = self.double_conv(512, 256)\n",
    "        self.up8 = nn.ConvTranspose2d(256, 128, kernel_size = 2, stride = 2)\n",
    "        self.conv8 = self.double_conv(256, 128)\n",
    "        self.up9 = nn.ConvTranspose2d(128, 64, kernel_size = 2, stride = 2)\n",
    "        self.conv9 = self.double_conv(128, 64)\n",
    "\n",
    "        # Output\n",
    "        self.conv10 = nn.Conv2d(64, out_channels, kernel_size = 1)\n",
    "\n",
    "    def double_conv(self, in_channels, out_channels):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size = 3, padding = 1),\n",
    "            nn.ReLU(inplace = True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Downsample path\n",
    "        c1 = self.conv1(x)\n",
    "        p1 = self.pool1(c1)\n",
    "        c2 = self.conv2(p1)\n",
    "        p2 = self.pool2(c2)\n",
    "        c3 = self.conv3(p2)\n",
    "        p3 = self.pool3(c3)\n",
    "        c4 = self.conv4(p3)\n",
    "        p4 = self.pool4(c4)\n",
    "\n",
    "        # Bottom\n",
    "        c5 = self.conv5(p4)\n",
    "\n",
    "        # Upsample path\n",
    "        # up6 = self.up6(c5)\n",
    "        up6 = F.interpolate(self.up6(c5), size=c4.size()[2:], mode='bilinear', align_corners=False)\n",
    "        merge6 = torch.cat([up6, c4], dim = 1)\n",
    "        c6 = self.conv6(merge6)\n",
    "\n",
    "        up7 = F.interpolate(self.up7(c6), size=c3.size()[2:], mode='bilinear', align_corners=False)\n",
    "        merge7 = torch.cat([up7, c3], dim = 1)\n",
    "        c7 = self.conv7(merge7)\n",
    "\n",
    "        up8 = F.interpolate(self.up8(c7), size=c2.size()[2:], mode='bilinear', align_corners=False)\n",
    "        merge8 = torch.cat([up8, c2], dim = 1)\n",
    "        c8 = self.conv8(merge8)\n",
    "\n",
    "        up9 = F.interpolate(self.up9(c8), size=c1.size()[2:], mode='bilinear', align_corners=False)\n",
    "        merge9 = torch.cat([up9, c1], dim = 1)\n",
    "        c9 = self.conv9(merge9)\n",
    "\n",
    "        # Output\n",
    "        out = self.conv10(c9)\n",
    "        return out\n",
    "    \n",
    "    def predict(self, x):\n",
    "        out = self.forward(x)\n",
    "        _, preds = torch.max(out, 1)\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecc3dba-9784-4a53-85d1-0328e357663c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalization(slice_2d):\n",
    "    max_val = np.max(slice_2d)\n",
    "    min_val = np.min(slice_2d)\n",
    "    # Only normalize if there is data\n",
    "    if max_val - min_val > 0:\n",
    "        slice_2d_normalized = (slice_2d - min_val) / (max_val - min_val)\n",
    "    else:\n",
    "        assert max_val == 0 and min_val == 0\n",
    "        slice_2d_normalized = slice_2d\n",
    "    return slice_2d_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34427d45-79f6-415d-b888-0fa498835395",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchio as tio\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from PIL import Image\n",
    "from torchvision.transforms import Compose\n",
    "from torch.autograd import Variable\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "device = \"cuda:2\"\n",
    "model = UNet(in_channels=2, out_channels=4)\n",
    "model = model.to(device)\n",
    "\n",
    "import re\n",
    "\n",
    "def atoi(text):\n",
    "    return int(text) if text.isdigit() else text\n",
    "\n",
    "def natural_keys(text):\n",
    "    return [ atoi(c) for c in re.split('(\\d+)', text) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c3ee360-6784-4311-8d50-1afd75bbfeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: BraTS-PED-00002-000-t1c.nii.gz\n",
      "Processing patient: BraTS-PED-00003-000-t1c.nii.gz\n",
      "Processing patient: BraTS-PED-00004-000-t1c.nii.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7782/1116958050.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;31m# Run the function for each orientation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0morientation\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"coronal\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"axial\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sagittal\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mprocess_orientation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morientation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_7782/1116958050.py\u001b[0m in \u001b[0;36mprocess_orientation\u001b[0;34m(orientation)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;31m# Save the segmentation slice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m             \u001b[0mseg_slices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;31m# Stack the segmentation slices to form a 3D image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_orientation(orientation):\n",
    "    if orientation == \"axial\":\n",
    "        model.load_state_dict(torch.load(\"unet_PED_axial.pth\"))\n",
    "    elif orientation == \"coronal\":\n",
    "        model.load_state_dict(torch.load(\"unet_PED_coronal.pth\"))\n",
    "    else:  # orientation == \"sagittal\"\n",
    "        model.load_state_dict(torch.load(\"unet_PED_sagittal.pth\"))\n",
    "\n",
    "    # Define the directories\n",
    "    t1c_dir = \"pediatric_modalities/t1c\"\n",
    "    t2f_dir = \"pediatric_modalities/t2f\"\n",
    "    output_dir =  \"PED_ax_op\"\n",
    "    original_seg_dir = \"ASNR-MICCAI-BraTS2023-PED-Challenge-TrainingData/\"\n",
    "\n",
    "    # Iterate over patient folders\n",
    "    for patient_dir in sorted(os.listdir(t1c_dir), key=natural_keys):\n",
    "        print(f\"Processing patient: {patient_dir}\")\n",
    "\n",
    "        t1c_img = nib.load(os.path.join(t1c_dir, patient_dir)).get_fdata()\n",
    "        t2f_img = nib.load(os.path.join(t2f_dir, patient_dir.replace(\"t1c\", \"t2f\"))).get_fdata()\n",
    "\n",
    "        # Placeholder for the output segmentation slices\n",
    "        seg_slices = []\n",
    "        \n",
    "        if orientation == \"axial\":\n",
    "            shape = t1c_img.shape[-1]\n",
    "        elif orientation == \"coronal\":\n",
    "            shape = t1c_img.shape[1]\n",
    "        else:\n",
    "            shape = t1c_img.shape[0]\n",
    "        \n",
    "        for i in range(shape):\n",
    "            if orientation == \"axial\":\n",
    "                t1c_img_slice = min_max_normalization(t1c_img[:, :, i])\n",
    "                t2f_img_slice = min_max_normalization(t2f_img[:, :, i])\n",
    "            elif orientation == \"coronal\":\n",
    "                t1c_img_slice = min_max_normalization(t1c_img[:, i, :])\n",
    "                t2f_img_slice = min_max_normalization(t2f_img[:, i, :])\n",
    "            else:  # orientation == \"sagittal\"\n",
    "                t1c_img_slice = min_max_normalization(t1c_img[i, :, :])\n",
    "                t2f_img_slice = min_max_normalization(t2f_img[i, :, :])\n",
    "\n",
    "            t1c_tensor = torch.from_numpy(np.array(t1c_img_slice,dtype = np.float32)[None, ...])\n",
    "\n",
    "            t2f_tensor = torch.from_numpy(np.array(t2f_img_slice,dtype = np.float32)[None, ...])\n",
    "\n",
    "            # Convert to tensors and stack\n",
    "            stack = torch.cat((t1c_tensor, t2f_tensor), dim=0).unsqueeze(0).to(device)\n",
    "            output = model(stack)\n",
    "\n",
    "            _, preds = torch.max(output, 1)\n",
    "\n",
    "            # Save the segmentation slice\n",
    "            seg_slices.append(preds.squeeze().detach().cpu().numpy())\n",
    "\n",
    "        # Stack the segmentation slices to form a 3D image\n",
    "        if orientation == \"axial\":\n",
    "            seg_3d = np.stack(seg_slices, axis=-1)\n",
    "        elif orientation == \"coronal\":\n",
    "            seg_3d = np.stack(seg_slices, axis=1)\n",
    "        else:  # orientation == \"sagittal\"\n",
    "            seg_3d = np.stack(seg_slices, axis=0)\n",
    "\n",
    "        # Load a original segmentation file to get the affine and header\n",
    "        original_seg_file = nib.load(os.path.join(original_seg_dir, patient_dir.replace('-t1c', '').split('.')[0], f\"{patient_dir.replace('-t1c', '').split('.')[0]}-seg.nii.gz\"))\n",
    "\n",
    "        # Convert the 3D image to a Nifti1Image and save\n",
    "        seg_nifti = nib.Nifti1Image(seg_3d, affine=original_seg_file.affine, header=original_seg_file.header)\n",
    "        nib.save(seg_nifti, os.path.join(output_dir, f\"{patient_dir}_{orientation}_segmentation.nii.gz\"))\n",
    "\n",
    "# Run the function for each orientation\n",
    "for orientation in [\"coronal\", \"axial\", \"sagittal\"]:\n",
    "    process_orientation(orientation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bfe046-5694-4bd2-82b2-000086df999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import zoom\n",
    "from scipy.stats import mode\n",
    "\n",
    "\n",
    "img1 = nib.load('BraTS-PED-00003-000-t1c.nii.gz_axial_segmentation.nii.gz') # change this code put a for loop\n",
    "img2 = nib.load(\"BraTS-PED-00003-000-t1c.nii.gz_coronal_segmentation.nii.gz\") \n",
    "img3 = nib.load(\"BraTS-PED-00003-000-t1c.nii.gz_sagittal_segmentation.nii.gz\")\n",
    "\n",
    "# Load your pre-trained models' predictions\n",
    "axial_preds = img1.get_fdata()\n",
    "coronal_preds = img2.get_fdata()\n",
    "sagittal_preds = img3.get_fdata()\n",
    "\n",
    "# Let's assume the dimensions of the original MRI are:\n",
    "original_shape = (240, 240, 155)  # Adjust as per your data\n",
    "\n",
    "# Rescale the predictions to the original dimensions:\n",
    "rescaled_axial = axial_preds\n",
    "rescaled_coronal = coronal_preds\n",
    "rescaled_sagittal = sagittal_preds\n",
    "\n",
    "# Combine the three predictions\n",
    "combined_preds = np.stack([rescaled_axial, rescaled_coronal, rescaled_sagittal])\n",
    "\n",
    "# Create the final segmentation by taking the majority vote\n",
    "final_segmentation = mode(combined_preds, axis=0)[0][0]\n",
    "\n",
    "# Create a Nifti image from the final segmentation\n",
    "# In your case, you might want to use the affine and header from one of the loaded NIfTI images\n",
    "final_seg_nifti = nib.Nifti1Image(final_segmentation, affine=img1.affine, header=img1.header)\n",
    "\n",
    "# Save the final segmentation\n",
    "nib.save(final_seg_nifti, \"final_segmentation.nii.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09328320-c448-4d5e-a421-b1f048ccc6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cb1e26-8d6f-4a39-9709-c3e5fe25e9eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677c6412-f3d9-47d8-87bd-1722ec245d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab954768-7db5-487b-abf4-e13730c5d21f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2da644-9f04-48ca-9ab2-7101f4f4fbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b82158-91c4-4045-9f8e-7ee41bb56d67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff03fad-f201-4a13-b963-f179e36cb2a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23100c3d-bf95-4a63-94cf-b40a2534ddc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad1071b-9ba8-4a70-980b-992f769bfd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0f2f8-3880-4db1-bbac-e48754323789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e14178-3b56-4b3d-88f4-bffcb8b9a73e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60e10ad-7b4f-4d57-b622-655830f774cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954243dd-6469-4264-b2b2-16840f79a237",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda-2022.10]",
   "language": "python",
   "name": "conda-env-anaconda-2022.10-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
